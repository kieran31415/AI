{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess the Word\n",
    "\n",
    "In the previous Notebook, we built and trained a Speech Recognition engine ourselves. Another possibility is to use one of the Speech Recognition services that are available for use online through an API. Many of these services offer Python SDKs, so Speech Recognition becomes really easy.\n",
    "\n",
    "Some important packages for the Speech Recognition are:\n",
    "\n",
    "- apiai\n",
    "- assemblyai\n",
    "- google-cloud-speech\n",
    "- pocketsphinx\n",
    "- SpeechRecognition\n",
    "- watson-developer-cloud\n",
    "- wit\n",
    "\n",
    "There is one package that stands out in terms of ease-of-use: *SpeechRecognition*. Instead of having to build scripts for accessing microphones and processing audio files from scratch, SpeechRecognition will have you up and running in just a few minutes.\n",
    "\n",
    "The SpeechRecognition library acts as a wrapper for several popular speech APIs and is thus extremely flexible. One of these —the Google Web Speech API — supports a default API key that is hard-coded into the SpeechRecognition library. That means you can get off your feet without having to sign up for a service. So, we'll use this 'SpeechRecognition' library as our Proof of Concept."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing SpeechRecognition\n",
    "\n",
    "You can install SpeechRecognition with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Using cached SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\u0040810\\onedrive - thomas more\\ai project\\2023_2024\\dl_env\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\u0040810\\onedrive - thomas more\\ai project\\2023_2024\\dl_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\u0040810\\onedrive - thomas more\\ai project\\2023_2024\\dl_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\u0040810\\onedrive - thomas more\\ai project\\2023_2024\\dl_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\u0040810\\onedrive - thomas more\\ai project\\2023_2024\\dl_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, you should verify the installation by typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "sr.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Recognizer Class\n",
    "\n",
    "All of the magic in SpeechRecognition happens with the *Recognizer class* (for more info: https://pypi.org/project/SpeechRecognition/).\n",
    "\n",
    "Once a Recognizer instance is created, you can use seven methods for recognizing speech from an audio source using various APIs. These are:\n",
    "\n",
    "- recognize_bing(): Microsoft Bing Speech\n",
    "- recognize_google(): Google Web Speech API\n",
    "- recognize_google_cloud(): Google Cloud Speech - requires installation of the google-cloud-speech package\n",
    "- recognize_houndify(): Houndify by SoundHound\n",
    "- recognize_ibm(): IBM Speech to Text\n",
    "- recognize_sphinx(): CMU Sphinx - requires installing PocketSphinx\n",
    "- recognize_wit(): Wit.ai\n",
    "\n",
    "Since SpeechRecognition ships with a default API key for the Google Web Speech API, you can get started with it right away. For this reason, we’ll use the Web Speech API in this Notebook. The other six APIs all require authentication with either an API key or a username/password combination. Remark: with the default Google Web Speech API key, you’ll be limited to only 50 requests per day, and there is no way to raise this quota. \n",
    "\n",
    "SpeechRecognition makes working with audio files easy thanks to its handy *AudioFile class*. This class can be initialized with the path to an audio file and provides methods for reading and working with the file’s contents. The *record()* method records the data from the entire file into an AudioData instance.\n",
    "\n",
    "So the complete code to read an audio file and recognize any speech in the audio, will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the still smell of old beer lingers it takes heat to bring out the odour a cold dip restores health exist a salt pickle taste fine with him go past or my favourite exist for food is the hot cross bun'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "harvard = sr.AudioFile('./audio_files/harvard.wav')\n",
    "with harvard as source:\n",
    "    audio = r.record(source)\n",
    "    \n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not perfect, but it does do a decent job, doesn't it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- Open the file in the audio_files map and listen if the transcription is correct.\n",
    "- Download an audio file and try to recognize the speech."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Capturing segments with offset and duration\n",
    "\n",
    "If you only want to capture a portion of the speech in a file, the record() method accepts a duration keyword argument that stops the recording after a specified number of seconds. In addition to specifying a recording duration, the record() method can be given a specific starting point using the offset keyword argument. This value represents the number of seconds from the beginning of the file to ignore before starting to record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stale smell of old beer lingers'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with harvard as source:\n",
    "    audio = r.record(source, duration=4)\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exceed to bring out the odour'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with harvard as source:\n",
    "    audio = r.record(source, offset=4.7, duration=2.8)\n",
    "\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The effect of noise\n",
    "\n",
    "Noise is a fact of life. All audio recordings have some degree of noise in them, and un-handled noise can wreck the accuracy of speech recognition apps.\n",
    "\n",
    "Listen to `jackhammer.wav` in the audio_files map. A lot of noise, right? The correct transcription should be: \"the stale smell of old beer lingers\". Let's try to recognize it from the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smelling fingers'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "jackhammer = sr.AudioFile('./audio_files/jackhammer.wav')\n",
    "with jackhammer as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably get rubbish output (because newer versions of the library handled the exception, see next paragraph, inside of the API block itself), or an error. \n",
    "\n",
    "\n",
    "Audio that cannot be matched to text by the API raises an UnknownValueError exception. You should always wrap calls to the API with try and except blocks to handle this exception. You know about exception handling from your other programming courses, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smelling fingers\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "jackhammer = sr.AudioFile('./audio_files/jackhammer.wav')\n",
    "with jackhammer as source:\n",
    "    audio = r.record(source)\n",
    "    \n",
    "try:\n",
    "    print(r.recognize_google(audio))\n",
    "except sr.RequestError:\n",
    "    print(\"API was unreachable or unresponsive\")\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Unable to recognize speech\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We handled the exception (or the API returned a rubbish value), but we weren't able to transcribe the file. One thing we can try, is using the `adjust_for_ambient_noise()` method of the Recognizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spell smell during windows'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "jackhammer = sr.AudioFile('./audio_files/jackhammer.wav')\n",
    "with jackhammer as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.record(source)\n",
    "\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not exactly what we expected of the sentence \"the stale smell of old beer lingers\". But at least we've got some output. \n",
    "\n",
    "When working with noisy files, it can be helpful to see the actual API response. Most APIs return a JSON string containing many possible transcriptions. The `recognize_google()` method will always return the most likely transcription unless you force it to give you the full response.\n",
    "\n",
    "You can do this by setting the show_all keyword argument of the recognize_google() method to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternative': [{'transcript': 'spell smell during windows',\n",
       "   'confidence': 0.60805869},\n",
       "  {'transcript': 'spell smell off your fingers'},\n",
       "  {'transcript': 'still smell up your windows'},\n",
       "  {'transcript': 'still smell your fingers'},\n",
       "  {'transcript': 'spell smell'}],\n",
       " 'final': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio, show_all=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, still not what we wanted. That means we need to do some more preprocessing on the input data. We need beter noise cancelling or filtering techniques. But, this is out of scope for this course."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with microphones\n",
    "\n",
    "To access your microphone with *SpeechRecognizer*, you’ll have to install the PyAudio package. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyAudio\n",
      "  Using cached PyAudio-0.2.13-cp310-cp310-win_amd64.whl (164 kB)\n",
      "Installing collected packages: PyAudio\n",
      "Successfully installed PyAudio-0.2.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyAudio\n",
    "# If pip installing PyAudio doesn't work on your Windows machine, you might want to try:\n",
    "#!pip install pipwin\n",
    "#!pipwin install pyaudio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of microphone names by calling the `list_microphone_names()` static method of the Microphone class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone (HP USB-C Dock Audio',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Headphones (HP USB-C Dock Audio',\n",
       " 'Primary Sound Capture Driver',\n",
       " 'Microphone (HP USB-C Dock Audio Headset)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Primary Sound Driver',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Headphones (HP USB-C Dock Audio Headset)',\n",
       " 'Headphones (HP USB-C Dock Audio Headset)',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Microphone (HP USB-C Dock Audio Headset)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Headphones (Realtek HD Audio 2nd output)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'Microphone Array (Realtek HD Audio Mic Array input)',\n",
       " 'Output (AMD HD Audio HDMI out #1)',\n",
       " 'Microphone (HP USB-C Dock Audio Headset)',\n",
       " 'Headphones (HP USB-C Dock Audio Headset)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the default system microphone by creating an instance of the Microphone class. If your system has no default microphone (such as on a RaspberryPi), or if you want to use a microphone other than the default, you will need to specify which one to use by supplying a device index (`mic = sr.Microphone(device_index=3)`).\n",
    "\n",
    "You can capture input from the microphone using the listen() method of the Recognizer class inside of the with block. This method takes an audio source as its first argument and records input from the source **until silence is detected**.\n",
    "\n",
    "Try speaking \"hello\" into your microphone. Wait a moment for the interpreter prompt to display again, then execute the recognize statement. Maybe try some other words, like \"f*** you\". Seems like Google is very polite. And maybe try to transcribe a complete sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\u0040810\\OneDrive - Thomas More\\AI Project\\2023_2024\\3. DL\\15. DL - Speech Recognition\\5. Guess the Word.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/u0040810/OneDrive%20-%20Thomas%20More/AI%20Project/2023_2024/3.%20DL/15.%20DL%20-%20Speech%20Recognition/5.%20Guess%20the%20Word.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mic \u001b[39m=\u001b[39m sr\u001b[39m.\u001b[39mMicrophone()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/u0040810/OneDrive%20-%20Thomas%20More/AI%20Project/2023_2024/3.%20DL/15.%20DL%20-%20Speech%20Recognition/5.%20Guess%20the%20Word.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m mic \u001b[39mas\u001b[39;00m source:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/u0040810/OneDrive%20-%20Thomas%20More/AI%20Project/2023_2024/3.%20DL/15.%20DL%20-%20Speech%20Recognition/5.%20Guess%20the%20Word.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     audio \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mlisten(source)\n",
      "File \u001b[1;32mc:\\Users\\u0040810\\OneDrive - Thomas More\\AI Project\\2023_2024\\DL_env\\lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[39mraise\u001b[39;00m WaitTimeoutError(\u001b[39m\"\u001b[39m\u001b[39mlistening timed out while waiting for phrase to start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\u0040810\\OneDrive - Thomas More\\AI Project\\2023_2024\\DL_env\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\u0040810\\OneDrive - Thomas More\\AI Project\\2023_2024\\DL_env\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "with mic as source:\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\u0040810\\OneDrive - Thomas More\\AI Project\\2023_2024\\3. DL\\15. DL - Speech Recognition\\5. Guess the Word.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/u0040810/OneDrive%20-%20Thomas%20More/AI%20Project/2023_2024/3.%20DL/15.%20DL%20-%20Speech%20Recognition/5.%20Guess%20the%20Word.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m r\u001b[39m.\u001b[39;49mrecognize_google(audio)\n",
      "File \u001b[1;32mc:\\Users\\u0040810\\OneDrive - Thomas More\\AI Project\\2023_2024\\DL_env\\lib\\site-packages\\speech_recognition\\__init__.py:728\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mif\u001b[39;00m show_all:\n\u001b[0;32m    726\u001b[0m     \u001b[39mreturn\u001b[39;00m actual_result\n\u001b[1;32m--> 728\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(actual_result, \u001b[39mdict\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(actual_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m, [])) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    731\u001b[0m     \u001b[39m# return alternative with highest confidence score\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     best_hypothesis \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m], key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m alternative: alternative[\u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the prompt never returns, your microphone is most likely picking up too much ambient noise.** As you know, you’ll need to use the adjust_for_ambient_noise() method.  Since input from a microphone is far less predictable than input from an audio file, it is a good idea to do this anytime you listen for microphone input. And also the try and except blocks are a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting if this works\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "try:\n",
    "    print(r.recognize_google(audio))\n",
    "except sr.RequestError:\n",
    "    print(\"API was unreachable or unresponsive\")\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Unable to recognize speech\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together: A \"Guess the Word\" Game\n",
    "\n",
    "Now that you’ve seen the basics of recognizing speech with the SpeechRecognition package let’s put your newfound knowledge to use and write a small game that picks a random word from a list and gives the user three attempts to guess the word.\n",
    "\n",
    "Here is the full code (try to understand the code, this shouldn't be a problem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import time\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    \"\"\"Transcribe speech from recorded from `microphone`.\n",
    "\n",
    "    Returns a dictionary with three keys:\n",
    "    \"success\": a boolean indicating whether or not the API request was\n",
    "               successful\n",
    "    \"error\":   `None` if no error occured, otherwise a string containing\n",
    "               an error message if the API could not be reached or\n",
    "               speech was unrecognizable\n",
    "    \"transcription\": `None` if speech could not be transcribed,\n",
    "               otherwise a string containing the transcribed text\n",
    "    \"\"\"\n",
    "    # check that recognizer and microphone arguments are appropriate type\n",
    "    if not isinstance(recognizer, sr.Recognizer):\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\n",
    "\n",
    "    if not isinstance(microphone, sr.Microphone):\n",
    "        raise TypeError(\"`microphone` must be `Microphone` instance\")\n",
    "\n",
    "    # adjust the recognizer sensitivity to ambient noise and record audio\n",
    "    # from the microphone\n",
    "    with microphone as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    # set up the response object\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    "\n",
    "    # try recognizing the speech in the recording\n",
    "    # if a RequestError or UnknownValueError exception is caught,\n",
    "    #     update the response object accordingly\n",
    "    try:\n",
    "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
    "    except sr.RequestError:\n",
    "        # API was unreachable or unresponsive\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable\"\n",
    "    except sr.UnknownValueError:\n",
    "        # speech was unintelligible\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # set the list of words, maxnumber of guesses, and prompt limit\n",
    "    WORDS = [\"apple\", \"banana\", \"grape\", \"orange\", \"mango\", \"lemon\"]\n",
    "    NUM_GUESSES = 3\n",
    "    PROMPT_LIMIT = 5\n",
    "\n",
    "    # create recognizer and mic instances\n",
    "    recognizer = sr.Recognizer()\n",
    "    microphone = sr.Microphone()\n",
    "\n",
    "    # get a random word from the list\n",
    "    word = random.choice(WORDS)\n",
    "\n",
    "    # format the instructions string\n",
    "    instructions = (\n",
    "        \"I'm thinking of one of these words:\\n\"\n",
    "        \"{words}\\n\"\n",
    "        \"You have {n} tries to guess which one.\\n\"\n",
    "    ).format(words=', '.join(WORDS), n=NUM_GUESSES)\n",
    "\n",
    "    # show instructions and wait 3 seconds before starting the game\n",
    "    print(instructions)\n",
    "    time.sleep(3)\n",
    "\n",
    "    for i in range(NUM_GUESSES):\n",
    "        # get the guess from the user\n",
    "        # if a transcription is returned, break out of the loop and\n",
    "        #     continue\n",
    "        # if no transcription returned and API request failed, break\n",
    "        #     loop and continue\n",
    "        # if API request succeeded but no transcription was returned,\n",
    "        #     re-prompt the user to say their guess again. Do this up\n",
    "        #     to PROMPT_LIMIT times\n",
    "        for j in range(PROMPT_LIMIT):\n",
    "            print('Guess {}. Speak!'.format(i+1))\n",
    "            guess = recognize_speech_from_mic(recognizer, microphone)\n",
    "            if guess[\"transcription\"]:\n",
    "                break\n",
    "            if not guess[\"success\"]:\n",
    "                break\n",
    "            print(\"I didn't catch that. What did you say?\\n\")\n",
    "\n",
    "        # if there was an error, stop the game\n",
    "        if guess[\"error\"]:\n",
    "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
    "            break\n",
    "\n",
    "        # show the user the transcription\n",
    "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
    "\n",
    "        # determine if guess is correct and if any attempts remain\n",
    "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\n",
    "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
    "\n",
    "        # determine if the user has won the game\n",
    "        # if not, repeat the loop if user has more attempts\n",
    "        # if no attempts left, the user loses the game\n",
    "        if guess_is_correct:\n",
    "            print(\"Correct! You win!\".format(word))\n",
    "            break\n",
    "        elif user_has_more_attempts:\n",
    "            print(\"Incorrect. Try again.\\n\")\n",
    "        else:\n",
    "            print(\"Sorry, you lose!\\nI was thinking of '{}'.\".format(word))\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recognizing Speech in languages other than English - Exercise\n",
    "\n",
    "Throughout this Notebook, we’ve been recognizing speech in English, which is the default language for each recognize_*() method of the SpeechRecognition package. However, it is absolutely possible to recognize speech in other languages, and this is quite simple to accomplish.\n",
    "\n",
    "To recognize speech in a different language, set the __language__ keyword argument of the recognize_*() method to a string corresponding to the desired language. Most of the methods accept a BCP-47 language tag, such as 'en-US' for American English, 'fr-FR' for French or __'nl-NL'__ for Dutch.\n",
    "\n",
    "Try to use the microphone to transcribe a Dutch (or other language) sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "775b7576bf7a34da706ed620d7f0d2338b0743a1fe22363e0994f105195362b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
